{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁCTICA 2 - NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESOLUCIÓN DEL CASO PRÁCTICO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importamos el corpus CESS del español, que es una colección de textos anotados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import cess_esp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Cargamos todas las frases anotadas del corpus CESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')], [('Una', 'di0fs0'), ('portavoz', 'nccs000'), ('de', 'sps00'), ('EDF', 'np00000'), ('explicó', 'vmis3s0'), ('a', 'sps00'), ('EFE', 'np00000'), ('que', 'cs'), ('el', 'da0ms0'), ('proyecto', 'ncms000'), ('para', 'sps00'), ('la', 'da0fs0'), ('construcción', 'ncfs000'), ('de', 'sps00'), ('Altamira_2', 'np00000'), (',', 'Fc'), ('al', 'spcms'), ('norte', 'ncms000'), ('de', 'sps00'), ('Tampico', 'np00000'), (',', 'Fc'), ('prevé', 'vmm02s0'), ('la', 'da0fs0'), ('utilización', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('natural', 'aq0cs0'), ('como', 'cs'), ('combustible', 'ncms000'), ('principal', 'aq0cs0'), ('en', 'sps00'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('ciclo', 'ncms000'), ('combinado', 'aq0msp'), ('que', 'pr0cn000'), ('debe', 'vmip3s0'), ('empezar', 'vmn0000'), ('a', 'sps00'), ('funcionar', 'vmn0000'), ('en', 'sps00'), ('mayo_del_2002', 'W'), ('.', 'Fp')], ...]\n"
     ]
    }
   ],
   "source": [
    "sents = cess_esp.tagged_sents()\n",
    "# print (sents)# -> comprobamos la carga y la comentamos para que no repercuta en el remdimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- Creamos un conjunto de entrenamiento y otro de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Metemos en el conjunto de entrenamiento el 90% de las frases, y el restante 10% en el conjunto de test\n",
    "training = []\n",
    "test = []\n",
    "for i in range(len(sents)):\n",
    "    if i % 10:\n",
    "        training.append(sents[i])\n",
    "    else:\n",
    "        test.append(sents[i])\n",
    "#print (\"1.- CONJUNTO DE ENTRENAMIENTO:\",training) -> comprobamos la carga y la comentamos para que no repercuta en el remdimiento\n",
    "#print (\"2.- CONJUNTO DE TEST:\", test) -> comprobamos la carga y la comentamos para que no repercuta en el remdimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.- Creamos cuatro (4) tipos distintos de analizadores morfológicos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - Un tagger basado en unigramas: aprende de la estadística de cada palabra encontrada en el corpus CESS\n",
    "# - Otro basado en bigramas: aprende de la estadística de una palabra y su palabra anterior\n",
    "# - Otro basado en trigramas: aprende a taggear una palabra basandose en la estadistica de la palabra y sus 2 anteriores\n",
    "# - Otro basado en Modelos Ocultos de Markov (en inglés Hidden Markov Models, HMM): es el modelo mas completo\n",
    "from nltk import UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger\n",
    "\n",
    "unigram_tagger = UnigramTagger(training)\n",
    "bigram_tagger = BigramTagger(training, backoff=unigram_tagger)\n",
    "trigram_tagger = TrigramTagger(training, backoff=bigram_tagger)\n",
    "hmm_tagger = HiddenMarkovModelTagger.train(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.- Probamos cada uno de los taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGGER UNIGRAMA: [('Los', 'da0mp0'), ('perros', 'ncmp000'), ('son', 'vsip3p0'), ('buenos', 'aq0mp0'), ('chuchetes', None)]\n",
      "________________________\n",
      "TAGGER BIGRAMA: [('Los', 'da0mp0'), ('perros', 'ncmp000'), ('son', 'vsip3p0'), ('buenos', 'aq0mp0'), ('chuchetes', None)]\n",
      "________________________\n",
      "TAGGER TRIGRAMA: [('Los', 'da0mp0'), ('perros', 'ncmp000'), ('son', 'vsip3p0'), ('buenos', 'aq0mp0'), ('chuchetes', None)]\n",
      "________________________\n",
      "TAGGER HMMs: [('Los', 'da0mp0'), ('perros', 'ncmp000'), ('son', 'vsip3p0'), ('buenos', 'aq0mp0'), ('chuchetes', 'ncmp000')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentence = \"Los perros son buenos chuchetes\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged = unigram_tagger.tag(tokens)\n",
    "print (\"TAGGER UNIGRAMA:\",tagged)\n",
    "print (\"________________________\")\n",
    "tagged = bigram_tagger.tag(tokens)\n",
    "print (\"TAGGER BIGRAMA:\",tagged)\n",
    "print (\"________________________\")\n",
    "tagged = trigram_tagger.tag(tokens)\n",
    "print (\"TAGGER TRIGRAMA:\",tagged)\n",
    "print (\"________________________\")\n",
    "tagged = hmm_tagger.tag(tokens)\n",
    "print (\"TAGGER HMMs:\",tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANTE: Vemos que el mejor tagger es el HMMs, que es capaza de identificar la palabra 'Chuchetes' de forma adecuada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.- Evaluamos sobre el conjunto de test que no utilizamos en el entrenamiento el porcentaje de acierto conseguido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con unigramas: 87.65970871234029\n",
      "Acierto con bigramas: 89.42636311057363\n",
      "Acierto con trigramas: 89.40007361059993\n",
      "Acierto con HMMs: 89.88905831011094\n"
     ]
    }
   ],
   "source": [
    "print ('Acierto con unigramas:', unigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con bigramas:', bigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con trigramas:', trigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con HMMs:', hmm_tagger.evaluate(test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos, de igual manera que el porcentaje de acierto para el tagger HMMs es el mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## COMENZAMOS EL EJERCICIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.- Descargamos el tagger para el corpus en catalán (\"cess_cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download()\n",
    "from nltk.corpus import cess_cat\n",
    "sents = cess_cat.tagged_sents()\n",
    "#Imprimimos el corpus cess_cat:\n",
    "#print (sents) -> comprobamos la carga y la comentamos para que no repercuta en el remdimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Metemos en el conjunto de entrenamiento el 90% de las frases, y el restante 10% en el conjunto de test\n",
    "training_cat = []\n",
    "test_cat = []\n",
    "for i in range(len(sents)):\n",
    "    if i % 10:\n",
    "        training_cat.append(sents[i])\n",
    "    else:\n",
    "        test_cat.append(sents[i])\n",
    "#print (\"1.- CONJUNTO DE ENTRENAMIENTO:\",training_cat) -> comprobamos la carga y la comentamos para que no repercuta en el remdimiento\n",
    "#print (\"2.- CONJUNTO DE TEST:\", test_cat) -> comprobamos la carga y la comentamos para que no repercuta en el remdimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Analizar frase en Catalán (\"el president de la Generalitat ha tingut 4 chuchetes\"). \n",
    "En un primer momento, vamos a hacerlo individualizado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.- Utilizando el tagger unigrama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGGER UNIGRAMA CAT: [('el', 'da0ms0'), ('president', None), ('de', 'sps00'), ('la', 'da0fs0'), ('Generalitat', 'np0000o'), ('ha', 'vaip3s0'), ('tingut', None), ('4', 'Z'), ('chuchetes', None)]\n"
     ]
    }
   ],
   "source": [
    "sentence_cat = \"el president de la Generalitat ha tingut 4 chuchetes\"\n",
    "tokens_cat = nltk.word_tokenize(sentence_cat)\n",
    "tagged_cat = unigram_tagger.tag(tokens_cat)\n",
    "print (\"TAGGER UNIGRAMA CAT:\",tagged_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.- Utilizando el tagger bigrama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGGER BIGRAMA CAT: [('el', 'da0ms0'), ('president', None), ('de', 'sps00'), ('la', 'da0fs0'), ('Generalitat', 'np0000o'), ('ha', 'vaip3s0'), ('tingut', None), ('4', 'Z'), ('chuchetes', None)]\n"
     ]
    }
   ],
   "source": [
    "sentence_cat = \"el president de la Generalitat ha tingut 4 chuchetes\"\n",
    "tokens_cat = nltk.word_tokenize(sentence_cat)\n",
    "tagged_cat = bigram_tagger.tag(tokens_cat)\n",
    "print (\"TAGGER BIGRAMA CAT:\",tagged_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.- Utilizando el tagger trigrama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGGER TRIGRAMA CAT: [('el', 'da0ms0'), ('president', None), ('de', 'sps00'), ('la', 'da0fs0'), ('Generalitat', 'np0000o'), ('ha', 'vaip3s0'), ('tingut', None), ('4', 'Z'), ('chuchetes', None)]\n"
     ]
    }
   ],
   "source": [
    "sentence_cat = \"el president de la Generalitat ha tingut 4 chuchetes\"\n",
    "tokens_cat = nltk.word_tokenize(sentence_cat)\n",
    "tagged_cat = trigram_tagger.tag(tokens_cat)\n",
    "print (\"TAGGER TRIGRAMA CAT:\",tagged_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimos el % de acierto para cada una de las opciones de análisis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con unigrama CATALAN: 41.38560961716003\n",
      "Acierto con bigrama CATALAN: 41.53489559802785\n",
      "Acierto con trigrama CATALAN: 41.525074151918126\n"
     ]
    }
   ],
   "source": [
    "print ('Acierto con unigrama CATALAN:', unigram_tagger.evaluate(test_cat)*100)\n",
    "print ('Acierto con bigrama CATALAN:', bigram_tagger.evaluate(test_cat)*100)\n",
    "print ('Acierto con trigrama CATALAN:', trigram_tagger.evaluate(test_cat)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.- Ahora realizamos el ejercicio siguiendo las pautas marcadas en el texto del mismo y que trasncribimos a continuación:\n",
    "\"El tagger entrenado (trigramTagger) en caso de fallar deberá devolver el resultado de un tagger de bigramas, que a su vez en caso de fallar devolverá uno de unigramas, que a su vez en caso de fallar deberá devolver el resultado de otro tagger. ¿Qué otro tagger? El que el alumno decida que es el más adecuado, tras leer el capitulo 5 del NLTK book\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos los datos de entrenamiento (90% del corpus seleccionado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con método propuesto: 91.83444970437448\n",
      "TAGGER TRIGRAMA CAT: [('el', 'da0ms0'), ('president', 'ncms000'), ('de', 'sps00'), ('la', 'da0fs0'), ('Generalitat', 'np0000o'), ('ha', 'vaip3s0'), ('tingut', 'vmp00sm'), ('4', 'Z'), ('chuchetes', 'NLTK_FASHION')]\n"
     ]
    }
   ],
   "source": [
    "# - Para ello utilizaremos:\n",
    "# - Un tagger basado en unigramas: aprende de la estadística de cada palabra encontrada en el corpus CESS\n",
    "# - Otro basado en bigramas: aprende de la estadística de una palabra y su palabra anterior\n",
    "# - Otro basado en trigramas: aprende a taggear una palabra basandose en la estadistica de la palabra y sus 2 anteriores\n",
    "# - Otro basado en el modelo 'Default' que es el seleccionado entre los existentes en la lectura propuesta del capítulo 5 del NLTK book, este tagger puede utilizar patrones o una cadena para el elemento no encontrado (el que utilizaremos: 'NLTK_FASHION')\n",
    "from nltk import UnigramTagger, BigramTagger, TrigramTagger, DefaultTagger\n",
    "\n",
    "#Trabajamos con los datos de entrenamiento 'training_cat' que suponen el 90% del corpus\n",
    "default_tagger = DefaultTagger ('NLTK_FASHION')\n",
    "unigram_tagger = UnigramTagger(training_cat, backoff=default_tagger)\n",
    "bigram_tagger = BigramTagger(training_cat, backoff=unigram_tagger)\n",
    "trigram_tagger = TrigramTagger(training_cat, backoff=bigram_tagger)\n",
    "#Evaluamos sobre el conjunto 'test_cat' que no utilizamos para el entrenamiento:\n",
    "print ('Acierto con método propuesto:',trigram_tagger.evaluate (test_cat)*100)\n",
    "#Mostramos los resultados de sus tags para cada token de la frase analizada (sentence_cat):\n",
    "sentence_cat = \"el president de la Generalitat ha tingut 4 chuchetes\"\n",
    "tokens_cat = nltk.word_tokenize(sentence_cat)\n",
    "tagged_cat = trigram_tagger.tag(tokens_cat)\n",
    "print (\"TAGGER TRIGRAMA CAT:\",tagged_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, simplemente a modo informativo, utilizamos los datos de test 'test_cat' (10% de corpus seleccionado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con método propuesto: 99.00017678602997\n",
      "TAGGER TRIGRAMA CAT: [('el', 'da0ms0'), ('president', 'ncms000'), ('de', 'sps00'), ('la', 'da0fs0'), ('Generalitat', 'np00000'), ('ha', 'vaip3s0'), ('tingut', 'vmp00sm'), ('4', 'Z'), ('chuchetes', 'NLTK_FASHION')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import UnigramTagger, BigramTagger, TrigramTagger, DefaultTagger\n",
    "\n",
    "default_tagger = DefaultTagger ('NLTK_FASHION')\n",
    "unigram_tagger = UnigramTagger(test_cat, backoff=default_tagger)\n",
    "bigram_tagger = BigramTagger(test_cat, backoff=unigram_tagger)\n",
    "trigram_tagger = TrigramTagger(test_cat, backoff=bigram_tagger)\n",
    "#Evaluamos sobre el propio conjunto 'test_cat':\n",
    "print ('Acierto con método propuesto:',trigram_tagger.evaluate (test_cat)*100)\n",
    "#Mostramos los resultados de sus tags para cada token de la frase analizada (sentence_cat):\n",
    "sentence_cat = \"el president de la Generalitat ha tingut 4 chuchetes\"\n",
    "tokens_cat = nltk.word_tokenize(sentence_cat)\n",
    "tagged_cat = trigram_tagger.tag(tokens_cat)\n",
    "print (\"TAGGER TRIGRAMA CAT:\",tagged_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.- Conclusión:\n",
    "- Resultado del tag 'chuchetes' obtenido en Castellano: 'ncmp000'\n",
    "- Resultado del tag 'chuchetes' obtenido en Catalán: 'NLTK_FASHION' (el sugerido como patrón para el método Default).\n",
    "Mediante el método en cadena propuesto en el ejercicio, se ha conseguido identificar correctamente cada token de la frase (cuestión que antes, cuando se analizaban los tagger por separado no obteníamos resultados por encima de un 41,53%)... pero 'chuchetes' sigue sin ser identificado..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
