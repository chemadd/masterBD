{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Texto: I didn't notice my animals were uglier than yours! I'm sorry...\n",
      "\n",
      "\n",
      "2. Frases: [\"I didn't notice my animals were uglier than yours!\", \"I'm sorry...\"]\n",
      "\n",
      "\n",
      "3. Tokens: ['I', 'did', \"n't\", 'notice', 'my', 'animals', 'were', 'uglier', 'than', 'yours', '!', 'I', \"'m\", 'sorry', '...']\n",
      "\n",
      "\n",
      "3. Tokens limpio: ['I', 'did', 'not', 'notice', 'my', 'animals', 'were', 'uglier', 'than', 'yours', 'I', 'am', 'sorry']\n",
      "\n",
      "\n",
      "4. Analisis Morfologico: [('I', 'PRP'), ('did', 'VBD'), ('not', 'RB'), ('notice', 'VB'), ('my', 'PRP$'), ('animals', 'NNS'), ('were', 'VBD'), ('uglier', 'JJR'), ('than', 'IN'), ('yours', 'JJR'), ('I', 'PRP'), ('am', 'VBP'), ('sorry', 'JJ')]\n",
      "\n",
      "\n",
      "\n",
      "7. Analisis sintactico:\n",
      "\n",
      "|.I .di.no.no.my.an.we.ug.th.yo.I .am.so.|\n",
      "|[--]  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] 'I'\n",
      "|.  [--]  .  .  .  .  .  .  .  .  .  .  .| [1:2] 'did'\n",
      "|.  .  [--]  .  .  .  .  .  .  .  .  .  .| [2:3] 'not'\n",
      "|.  .  .  [--]  .  .  .  .  .  .  .  .  .| [3:4] 'notice'\n",
      "|.  .  .  .  [--]  .  .  .  .  .  .  .  .| [4:5] 'my'\n",
      "|.  .  .  .  .  [--]  .  .  .  .  .  .  .| [5:6] 'animals'\n",
      "|.  .  .  .  .  .  [--]  .  .  .  .  .  .| [6:7] 'were'\n",
      "|.  .  .  .  .  .  .  [--]  .  .  .  .  .| [7:8] 'uglier'\n",
      "|.  .  .  .  .  .  .  .  [--]  .  .  .  .| [8:9] 'than'\n",
      "|.  .  .  .  .  .  .  .  .  [--]  .  .  .| [9:10] 'yours'\n",
      "|.  .  .  .  .  .  .  .  .  .  [--]  .  .| [10:11] 'I'\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [--]  .| [11:12] 'am'\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [--]| [12:13] 'sorry'\n",
      "|[--]  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] NP -> 'I' *\n",
      "|[-->  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] S  -> NP * VP\n",
      "|.  [--]  .  .  .  .  .  .  .  .  .  .  .| [1:2] V  -> 'did' *\n",
      "|.  [-->  .  .  .  .  .  .  .  .  .  .  .| [1:2] VP -> V * NP\n",
      "|.  .  [--]  .  .  .  .  .  .  .  .  .  .| [2:3] P  -> 'not' *\n",
      "|.  .  [-->  .  .  .  .  .  .  .  .  .  .| [2:3] PP -> P * NP\n",
      "|.  .  .  [--]  .  .  .  .  .  .  .  .  .| [3:4] V  -> 'notice' *\n",
      "|.  .  .  [-->  .  .  .  .  .  .  .  .  .| [3:4] VP -> V * NP\n",
      "|.  .  .  .  [--]  .  .  .  .  .  .  .  .| [4:5] Det -> 'my' *\n",
      "|.  .  .  .  [-->  .  .  .  .  .  .  .  .| [4:5] NP -> Det * N\n",
      "|.  .  .  .  [-->  .  .  .  .  .  .  .  .| [4:5] NP -> Det * N PP\n",
      "|.  .  .  .  .  [--]  .  .  .  .  .  .  .| [5:6] N  -> 'animals' *\n",
      "|.  .  .  .  [-----]  .  .  .  .  .  .  .| [4:6] NP -> Det N *\n",
      "|.  .  .  .  [----->  .  .  .  .  .  .  .| [4:6] NP -> Det N * PP\n",
      "|.  .  .  .  [----->  .  .  .  .  .  .  .| [4:6] S  -> NP * VP\n",
      "|.  .  .  [--------]  .  .  .  .  .  .  .| [3:6] VP -> V NP *\n",
      "|.  .  .  [-------->  .  .  .  .  .  .  .| [3:6] VP -> VP * PP\n",
      "|.  .  .  .  .  .  [--]  .  .  .  .  .  .| [6:7] V  -> 'were' *\n",
      "|.  .  .  .  .  .  [-->  .  .  .  .  .  .| [6:7] VP -> V * NP\n",
      "|.  .  .  .  .  .  .  [--]  .  .  .  .  .| [7:8] Det -> 'uglier' *\n",
      "|.  .  .  .  .  .  .  [-->  .  .  .  .  .| [7:8] NP -> Det * N\n",
      "|.  .  .  .  .  .  .  [-->  .  .  .  .  .| [7:8] NP -> Det * N PP\n",
      "|.  .  .  .  .  .  .  .  [--]  .  .  .  .| [8:9] P  -> 'than' *\n",
      "|.  .  .  .  .  .  .  .  [-->  .  .  .  .| [8:9] PP -> P * NP\n",
      "|.  .  .  .  .  .  .  .  .  [--]  .  .  .| [9:10] Det -> 'yours' *\n",
      "|.  .  .  .  .  .  .  .  .  [-->  .  .  .| [9:10] NP -> Det * N\n",
      "|.  .  .  .  .  .  .  .  .  [-->  .  .  .| [9:10] NP -> Det * N PP\n",
      "|.  .  .  .  .  .  .  .  .  .  [--]  .  .| [10:11] NP -> 'I' *\n",
      "|.  .  .  .  .  .  .  .  .  .  [-->  .  .| [10:11] S  -> NP * VP\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [--]  .| [11:12] V  -> 'am' *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [-->  .| [11:12] VP -> V * NP\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [--]| [12:13] Det -> 'sorry' *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [-->| [12:13] NP -> Det * N\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [-->| [12:13] NP -> Det * N PP\n"
     ]
    }
   ],
   "source": [
    "#*************************************************************************\n",
    "#1.Importamos la libreria NLTK\n",
    "#*************************************************************************\n",
    "import nltk\n",
    "\n",
    "\n",
    "#*************************************************************************\n",
    "#2.Creamos una texto de entrada a nuestra cadena NLP\n",
    "#*************************************************************************\n",
    "text = \"I didn't notice my animals were uglier than yours! I'm sorry...\"\n",
    "print (\"\\n\\n1. Texto:\",text)\n",
    "\n",
    "\n",
    "#*************************************************************************\n",
    "#2.Dividimos el texto en frases\n",
    "#*************************************************************************\n",
    "sentences = nltk.tokenize.sent_tokenize(text)\n",
    "print (\"\\n\\n2. Frases:\",sentences)\n",
    "\n",
    "\n",
    "#*****************************************************************************\n",
    "#3.Tokenización: tokenizamos el texto, es decir dividimos el texto en tokens\n",
    "#*****************************************************************************\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tokensLimpio = []\n",
    "print (\"\\n\\n3. Tokens:\",tokens)\n",
    "for (tok) in tokens:\n",
    "    #wordnet no contiene las formas abreviadas 'm  y  n't así que las introducimos nosotros para que lematice bien\n",
    "    if tok=='\\'m':\n",
    "        tok = 'am'\n",
    "    if tok=='\\'s':\n",
    "        tok = 'is'\n",
    "    if tok=='n\\'t':\n",
    "        tok = 'not'\n",
    "    if tok!='!' and tok!='...':\n",
    "        tokensLimpio.append(tok)\n",
    "print (\"\\n\\n3. Tokens limpio:\",tokensLimpio)\n",
    "        \n",
    "#*************************************************************************\n",
    "#4.Análisis morfológico: asignamos una etiqueta morfologica a cada token\n",
    "#*************************************************************************\n",
    "tagged = nltk.pos_tag(tokensLimpio)\n",
    "print (\"\\n\\n4. Analisis Morfologico:\",tagged)\n",
    "\n",
    "\n",
    "#*******************************************************************    \n",
    "#7.Análisis sintáctico\n",
    "#******************************************************************* \n",
    "sent = tokensLimpio\n",
    "\n",
    "#Creamos nuestra propia Gramatica Libre de Contexto (en inglés CFG)\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my' | 'yours' | 'sorry' | 'uglier'\n",
    "N -> 'animals'\n",
    "V -> 'notice' | 'did' | 'were' | 'am'\n",
    "P -> 'in' | 'not' | 'than'\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "#Generamos un parser sintáctico capaz de reconocer la gramática\n",
    "parser = nltk.ChartParser(grammar, trace=1)\n",
    "print ('\\n\\n\\n7. Analisis sintactico:\\n')\n",
    "for tree in parser.parse(tokensLimpio):\n",
    "    print(tree,'\\n')\n",
    "    tree.draw()\n",
    "# nltk.parse.chart.demo(2, print_times=False, trace=1, sent='I saw a dog', numparses=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
