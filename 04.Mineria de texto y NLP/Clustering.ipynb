{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Cargamos el corpus\n",
      "['Me gustan las vacas', 'Me gustan los caballos', 'odio los perros', 'odio los caballos', 'me gustan las ranas', 'me gusta el helado', 'no quiero comer', 'los helados son cremosos']\n",
      "\n",
      "\n",
      "2. Vectorizamos los textos\n",
      "Atributos: ['caballos', 'comer', 'cremosos', 'el', 'gusta', 'gustan', 'helado', 'helados', 'las', 'los', 'me', 'no', 'odio', 'perros', 'quiero', 'ranas', 'son', 'vacas']\n",
      "Matriz tf:\n",
      " [[0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0]]\n",
      "nº de muestras: 8, nº de atributos: 18\n",
      "\n",
      "\n",
      "3. Clusterizamos los textos\n",
      "Clusters: [1 1 0 0 1 1 0 0]\n",
      "\n",
      "Cluster 0 :\n",
      "\t odio los perros\n",
      "\t odio los caballos\n",
      "\t no quiero comer\n",
      "\t los helados son cremosos\n",
      "\n",
      "Cluster 1 :\n",
      "\t Me gustan las vacas\n",
      "\t Me gustan los caballos\n",
      "\t me gustan las ranas\n",
      "\t me gusta el helado\n",
      "\n",
      "\n",
      "4. Medimos la calidad de nuestro cluster\n",
      "Clusters:     [1 1 0 0 1 1 0 0]\n",
      "Ground Truth: [1, 1, 0, 0, 1, 1, 0, 1]\n",
      "Homogeneity: 0.575\n",
      "Completeness: 0.549\n",
      "V-measure: 0.562\n",
      "\n",
      "\n",
      "4. Clasificamos un nuevo texto entrante\n",
      "Nuevo texto: ['odio los animales']\n",
      "Nueva matriz tf: [[0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]]\n",
      "Prediccion: Cluster 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#***************************************************************************************\n",
    "# 1. Cargamos el corpus de textos\n",
    "#***************************************************************************************\n",
    "\n",
    "print(\"\\n\\n1. Cargamos el corpus\")\n",
    "trainCorpus = [\"Me gustan las vacas\",\n",
    "               \"Me gustan los caballos\",\n",
    "               \"odio los perros\",\n",
    "               \"odio los caballos\",\n",
    "               \"me gustan las ranas\",\n",
    "               \"me gusta el helado\",\n",
    "               \"no quiero comer\",\n",
    "               \"los helados son cremosos\"]\n",
    "print (trainCorpus)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#*********************************************************************************************************\n",
    "# 2. Vectorizamos los textos del corpus (convertimos cada texto en un vector de frecuencias de palabras)\n",
    "#*********************************************************************************************************\n",
    "print(\"\\n\\n2. Vectorizamos los textos\")\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "\n",
    "#Transformamos los documentos en una matriz de tf's de documentos.\n",
    "vectorizer.fit(trainCorpus) #El vectorizador aprende el vocabulario del corpus\n",
    "print (\"Atributos:\",vectorizer.get_feature_names())\n",
    "tfMatrix = vectorizer.transform(trainCorpus) #Extraemos las frecuencias de palabras (tf)\n",
    "print (\"Matriz tf:\\n\",tfMatrix.toarray())\n",
    "\n",
    "\n",
    "#La matriz tf es nuestro dataset, donde:\n",
    "# - cada fila representa una muestra (un documento del corpus)\n",
    "# - cada columna representa un atributo (la frecuencia de una palabra en dicho documento)\n",
    "print(\"nº de muestras: %d, nº de atributos: %d\" % tfMatrix.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#***************************************************************************************\n",
    "# 3. Clusterizamos los documentos mediante el algoritmo K-means\n",
    "#***************************************************************************************\n",
    "print(\"\\n\\n3. Clusterizamos los textos\")\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "#Asignamos a kmeans un valor de k=2, es decir que el algoritmo intentará encontrar 2 clusters\n",
    "k=2\n",
    "km = KMeans(n_clusters=k,max_iter=100)\n",
    "km.fit(tfMatrix)\n",
    "print (\"Clusters:\",km.labels_)\n",
    "for i in range(k):\n",
    "    print (\"\\nCluster\",i,\":\")\n",
    "    for j in range(km.labels_.size):\n",
    "        if km.labels_[j]==i:\n",
    "            print (\"\\t\",trainCorpus[j])\n",
    "\n",
    "\n",
    "\n",
    "#***************************************************************************************\n",
    "# 4. Medimos la calidad de nuestro cluster\n",
    "#***************************************************************************************\n",
    "print(\"\\n\\n4. Medimos la calidad de nuestro cluster\")\n",
    "\n",
    "#Ground truth son las categorias correctas puestas a mano (1= texto positivo, 0=negativo), para comparar con las automaticas de kmeans\n",
    "groundTruth = [1,1,0,0,1,1,0,1] \n",
    "print (\"Clusters:    \",km.labels_)\n",
    "print (\"Ground Truth:\",groundTruth)\n",
    "\n",
    "\n",
    "#Un cluster es homogéneo si todos sus elementos contienen miembros de una misma clase\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(groundTruth, km.labels_))\n",
    "\n",
    "#Una clase es completa si todos sus elementos pertenecen al mismo cluster\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(groundTruth, km.labels_))\n",
    "\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(groundTruth, km.labels_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#***************************************************************************************\n",
    "# 5. Usamos los clusters previos para clasificar un nuevo texto entrante\n",
    "#***************************************************************************************\n",
    "print(\"\\n\\n4. Clasificamos un nuevo texto entrante\")\n",
    "\n",
    "testCorpus = [\"odio los animales\"]\n",
    "tfMatrixTest =  vectorizer.transform(testCorpus)\n",
    "print (\"Nuevo texto:\",testCorpus)\n",
    "print (\"Nueva matriz tf:\",tfMatrixTest.toarray() )\n",
    "\n",
    "prediction = km.predict(tfMatrixTest)[0]\n",
    "print (\"Prediccion: Cluster\",prediction)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
