---
title: "Caso Pŕactico Final"
output:
  pdf_document: default
  html_notebook: default
  html_document: default
---

Tomaremos el dataset de aprobación de crédito bancario en https://archive.ics.uci.edu/ml/datasets/Credit+Approval . Los datos también se pueden cargar de la carpeta de contenido en  `crx.data`. La información del dataset está en https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.names y expone lo siguiente:

      1. Title: Credit Approval

      2. Sources: 
          (confidential)
          Submitted by quinlan@cs.su.oz.au
      
      3.  Past Usage:
      
          See Quinlan,
          * "Simplifying decision trees", Int J Man-Machine Studies 27,
            Dec 1987, pp. 221-234.
          * "C4.5: Programs for Machine Learning", Morgan Kaufmann, Oct 1992
        
      4.  Relevant Information:
      
          This file concerns credit card applications.  All attribute names
          and values have been changed to meaningless symbols to protect
          confidentiality of the data.
        
          This dataset is interesting because there is a good mix of
          attributes -- continuous, nominal with small numbers of
          values, and nominal with larger numbers of values.  There
          are also a few missing values.
        
      5.  Number of Instances: 690
      
      6.  Number of Attributes: 15 + class attribute
      
      7.  Attribute Information:
      
          A1:	b, a.
          A2:	continuous.
          A3:	continuous.
          A4:	u, y, l, t.
          A5:	g, p, gg.
          A6:	c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.
          A7:	v, h, bb, j, n, z, dd, ff, o.
          A8:	continuous.
          A9:	t, f.
          A10:	t, f.
          A11:	continuous.
          A12:	t, f.
          A13:	g, p, s.
          A14:	continuous.
          A15:	continuous.
          A16: +,-         (class attribute)
      
      8.  Missing Attribute Values:
          37 cases (5%) have one or more missing values.  The missing
          values from particular attributes are:
      
          A1:  12
          A2:  12
          A4:   6
          A5:   6
          A6:   9
          A7:   9
          A14: 13
      
      9.  Class Distribution
        
          +: 307 (44.5%)
          -: 383 (55.5%)
      
## Actividades a realizar

## 1. Carga los datos. 
Realiza una inspección por variables de la distribución de aprobación de crédito en función de cada atributo visualmente. Realiza las observaciones pertinentes. ¿ Qué variables son mejores para separar los datos?
```{r}
CreApp <- read.csv('https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data',header= F,sep = ',')
write.csv(CreApp, 'CreditApproval.csv')
# Revision de datos
colnames(CreApp) <- c('A1','A2','A3','A4','A5','A6','A7','A8','A9','A10','A11','A12','A13','A14','A15','CreditApproval')
summary (CreApp)
CreApp
```
# Graficamos V16 frente al resto de atributos

```{r}
# Graficamos V16 frente al resto de atributos
library(ggplot2)
ggplot(CreApp, aes(A1,fill=CreditApproval))+geom_bar()
ggplot(CreApp, aes(as.numeric(CreApp$A2),fill=CreditApproval))+geom_histogram(binwidth=25)
ggplot(CreApp, aes(as.numeric(CreApp$A3),fill=CreditApproval))+geom_histogram(binwidth=2)
ggplot(CreApp, aes(A4,fill=CreditApproval))+geom_bar()
ggplot(CreApp, aes(A5,fill=CreditApproval))+geom_bar()
ggplot(CreApp, aes(A6,fill=CreditApproval))+geom_bar()
ggplot(CreApp, aes(A7,fill=CreditApproval))+geom_bar()
ggplot(CreApp, aes(as.numeric(CreApp$A8),fill=CreditApproval))+geom_histogram(binwidth=2)
# Cuanto menor A8, mayor probabilidad de rechazo del credito
ggplot(CreApp, aes(A9,fill=CreditApproval))+geom_bar()
# A9 discrimina mucho ya que la mayor parte de f's tiene aprobacion negativa y la mayor parte de t's la tienen positiva
ggplot(CreApp, aes(A10,fill=CreditApproval))+geom_bar()
# A10 tambien discrimina mucho ya que la mayor parte de f's tiene aprobacion negativa y la mayor parte de t's la tienen positiva
ggplot(CreApp, aes(as.numeric(CreApp$A11),fill=CreditApproval))+geom_histogram(binwidth=5)
# Los que mayor probabilidad de rechazo tienen son los de menor A11
ggplot(CreApp, aes(A12,fill=CreditApproval))+geom_bar()
ggplot(CreApp, aes(A13,fill=CreditApproval))+geom_bar()
ggplot(CreApp, aes(as.numeric(CreApp$A14),fill=CreditApproval))+geom_histogram(binwidth=15)
ggplot(CreApp, aes(A15, fill=CreditApproval))+geom_histogram(binwidth=2000)
# Se observa que los creditos de mayor cantidad de A15 tienen mayor probabilidad de concederse, relacionados seguramente con las variables A9 o A10
```
# Preparar el dataset
2. Prepara el dataset convenientemente e imputa los valores faltantes usando la librería `missForest`
```{r}
# install.packages("missForest")
library(missForest)

```

3. Divide el dataset tomando las primeras 590 instancias como train y las últimas 100 como test.
4. Entrena un modelo de regresión logística con regularización Ridge y Lasso en train seleccionando el que mejor **AUC** tenga. Da las métricas en test.
5. Aporta los *log odds* de las variables predictoras sobre la variable objetivo.
6. Si por cada verdadero positivo ganamos 100e y por cada falso positivo perdemos 20e. ¿ Qué rentabilidad aporta aplicar este modelo?

