{"cells":[{"cell_type":"markdown","source":["# Caso práctico de Analítica Escalable (Ejercicios) #"],"metadata":{}},{"cell_type":"markdown","source":["En este notebook, se van a realizar los ejercicios del módulo. En lugar de tener contenido teórico y descripciones, se dejarán únicamente las celdas de código necesarias para su ejecución.\n\nPara completar los ejercicios, hay que codificar y ejecutar la solución en las celdas que se encuentran justo debajo de los enunciados de los ejercicios.\n\nUna vez se haya terminado, en el menú de la izquiera, a la hora de seleccionar el notebook, si se le hace click a la flecha que se encuentra en la derecha, se puede exportar al notebook. Hay que exportarlo en formato DBC (Databricks Notebook) como en HTML."],"metadata":{}},{"cell_type":"code","source":["print sc.version"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansicyan\">  File </span><span class=\"ansigreen\">&quot;&lt;command-4027673054087824&gt;&quot;</span><span class=\"ansicyan\">, line </span><span class=\"ansigreen\">1</span>\n<span class=\"ansiyellow\">    print sc.version</span>\n<span class=\"ansigrey\">           ^</span>\n<span class=\"ansired\">SyntaxError</span><span class=\"ansired\">:</span> Missing parentheses in call to &apos;print&apos;\n</div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["Los ejercicios consistirán en añadir nuevas funcionalidades, o ejecutar nuevo código, sobre el Notebook que contiene toda la teoría vista en el módulo. Por ello, gran parte del código que se encuentra dentro del notebook de contenido teórico se encontrará aquí de nuevo, pero se pedirá nuevo código."],"metadata":{}},{"cell_type":"markdown","source":["## Importando los datos ##"],"metadata":{}},{"cell_type":"code","source":["dbutils.fs.cp(\"/FileStore/tables/Hotel_Reviews.csv\", \"file:///databricks/driver/Hotel_Reviews.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">2</span><span class=\"ansired\">]: </span>True\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["def score_to_string(score):\n  if score < 5:\n    return \"Bad\"\n  elif score < 7:\n    return \"Normal\"\n  elif score < 9:\n    return \"Good\"\n  elif score < 10: \n    return \"Excellent\"\n  else:\n    return \"Perfect\"\n  \ndef score_to_evaluation(score_string):\n  score_dict = {\n    \"Bad\": 0,\n    \"Normal\": 1,\n    \"Good\": 2,\n    \"Excellent\": 3,\n    \"Perfect\": 4\n  }\n  return score_dict.get(score_string, None)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["## DataFrames en Spark: SparkSQL. ##"],"metadata":{}},{"cell_type":"code","source":["df_spark_sql = spark.read.format(\"csv\")\\\n         .option(\"header\", \"true\")\\\n         .option(\"inferSchema\", \"true\")\\\n         .load(\"file:///databricks/driver/Hotel_Reviews.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["from pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType, IntegerType\n\nscore_string_udf = udf(score_to_string, StringType())\nscore_evaluation_udf = udf(score_to_evaluation, IntegerType())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["df_spark_sql = df_spark_sql.withColumn('score_string',score_string_udf(df_spark_sql[\"Average_Score\"]))\ndf_spark_sql = df_spark_sql.withColumn('score_evaluation',score_evaluation_udf(df_spark_sql[\"score_string\"]))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["def day_to_int(day):\n  return int(day.replace(\" days\", \"\").replace(\" day\", \"\"))\nday_to_int_udf = udf(day_to_int, IntegerType())\ndf_spark_sql = df_spark_sql.withColumn(\"days_since_review\", day_to_int_udf(df_spark_sql[\"days_since_review\"]))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["### Ejercicio 1: Crear un bucle que muestre todas las columnas del DataFrame, junto con sus tipos. También puedes pintar el esquema del Dataframe. ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejericicio\n# \nprint(\"Primero imprimimos el esquema:\")\nprint(df_spark_sql.printSchema())\nprint(\"Ahora hacemos el bucle que muestra las columnas y tipos del dataFrame\")\nfor name, dtype in df_spark_sql.dtypes:\n  print(name, \" --> \",dtype)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Primero imprimimos el esquema:\nroot\n-- Hotel_Address: string (nullable = true)\n-- Additional_Number_of_Scoring: integer (nullable = true)\n-- Review_Date: string (nullable = true)\n-- Average_Score: double (nullable = true)\n-- Hotel_Name: string (nullable = true)\n-- Reviewer_Nationality: string (nullable = true)\n-- Negative_Review: string (nullable = true)\n-- Review_Total_Negative_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews: integer (nullable = true)\n-- Positive_Review: string (nullable = true)\n-- Review_Total_Positive_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews_Reviewer_Has_Given: integer (nullable = true)\n-- Reviewer_Score: double (nullable = true)\n-- Tags: string (nullable = true)\n-- days_since_review: integer (nullable = true)\n-- lat: string (nullable = true)\n-- lng: string (nullable = true)\n-- score_string: string (nullable = true)\n-- score_evaluation: integer (nullable = true)\n\nNone\nAhora hacemos el bucle que muestra las columnas y tipos del dataFrame\nHotel_Address  --&gt;  string\nAdditional_Number_of_Scoring  --&gt;  int\nReview_Date  --&gt;  string\nAverage_Score  --&gt;  double\nHotel_Name  --&gt;  string\nReviewer_Nationality  --&gt;  string\nNegative_Review  --&gt;  string\nReview_Total_Negative_Word_Counts  --&gt;  int\nTotal_Number_of_Reviews  --&gt;  int\nPositive_Review  --&gt;  string\nReview_Total_Positive_Word_Counts  --&gt;  int\nTotal_Number_of_Reviews_Reviewer_Has_Given  --&gt;  int\nReviewer_Score  --&gt;  double\nTags  --&gt;  string\ndays_since_review  --&gt;  int\nlat  --&gt;  string\nlng  --&gt;  string\nscore_string  --&gt;  string\nscore_evaluation  --&gt;  int\n</div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["### Ejercicio 2: Realizar un muestreo de 10 valores únicos de nombres de hoteles. Ordénalos alfanuméricamente de forma ascendente (primero los números 0-9, después A-Z). ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\ndf_spark_sql.select('Hotel_Name').distinct().limit(10).orderBy(\"Hotel_Name\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+\n          Hotel_Name|\n+--------------------+\n      Avenida Palace|\nBest Western Sera...|\nGrange Holborn Hotel|\nH tel Barri re Le...|\nH tel Elysees Mermoz|\n H10 Port Vell 4 Sup|\n         HCC Regente|\nHyatt Regency Ams...|\nMelia Paris Notre...|\nMelia Paris Tour ...|\n+--------------------+\n\n</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["### Ejercicio 3: Transforma las columnas *lat* y *lng* al tipo Float."],"metadata":{}},{"cell_type":"code","source":["# Transformación de la columna sin utilizar UDF.\nfrom pyspark.sql.types import FloatType\n\ndf_new_aux = df_spark_sql.withColumn(\"lat\", df_spark_sql[\"lat\"].cast(FloatType()) )\ndf_new_sql = df_new_aux.withColumn(\"lng\", df_spark_sql[\"lng\"].cast(FloatType()) )\ndf_spark_sql = df_new_sql\nprint ('  ----  Comprobamos que ha cambiado ------ ')\nprint(df_spark_sql.printSchema())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">  ----  Comprobamos que ha cambiado ------ \nroot\n-- Hotel_Address: string (nullable = true)\n-- Additional_Number_of_Scoring: integer (nullable = true)\n-- Review_Date: string (nullable = true)\n-- Average_Score: double (nullable = true)\n-- Hotel_Name: string (nullable = true)\n-- Reviewer_Nationality: string (nullable = true)\n-- Negative_Review: string (nullable = true)\n-- Review_Total_Negative_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews: integer (nullable = true)\n-- Positive_Review: string (nullable = true)\n-- Review_Total_Positive_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews_Reviewer_Has_Given: integer (nullable = true)\n-- Reviewer_Score: double (nullable = true)\n-- Tags: string (nullable = true)\n-- days_since_review: integer (nullable = true)\n-- lat: float (nullable = true)\n-- lng: float (nullable = true)\n-- score_string: string (nullable = true)\n-- score_evaluation: integer (nullable = true)\n\nNone\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["splits = df_spark_sql.randomSplit([0.67, 0.33])\ndf_spark_sql_train = splits[0].dropna()\ndf_spark_sql_test = splits[1].dropna()\nprint(df_spark_sql_train.count())\nprint(df_spark_sql_test.count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">343059\n169411\n</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["### Ejercicio 4: ¿Cuántos hoteles tienen una puntuación de 'Perfect'? ¿Y 'Good'? ¿Y 'Normal' junto a 'Good'? (Utilizar el dataset de Train)"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\nprint ('  ----  Cantidad de Perfect ------ ')\ndf_spark_sql_train.select('score_string').filter(\"score_string = 'Perfect'\").groupBy('score_string').count().show()\nprint ('  ----  Cantidad de Good ------ ')\ndf_spark_sql_train.select('score_string').filter(\"score_string = 'Good'\").groupBy('score_string').count().show()\nprint ('  ----  Cantidad de Normal y Good ------ ')\ndf_spark_sql_train.select('score_string').filter(\"score_string = 'Normal' or score_string = 'Good'\").groupBy('score_string').count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">  ----  Cantidad de Perfect ------ \n+------------+-----+\nscore_string|count|\n+------------+-----+\n+------------+-----+\n\n  ----  Cantidad de Good ------ \n+------------+------+\nscore_string| count|\n+------------+------+\n        Good|286020|\n+------------+------+\n\n  ----  Cantidad de Normal y Good ------ \n+------------+------+\nscore_string| count|\n+------------+------+\n        Good|286020|\n      Normal|  3769|\n+------------+------+\n\n</div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["### Ejercicio 5: Obtener los hoteles con mayor puntuación media, descartando todos los que tengan una puntuación por encima de Good. (Utilizar el dataset de Train) ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\nfrom pyspark.sql.functions import desc\n# df_spark_sql_train.limit(1000).show()\nprint ('  ----  10 Hoteles no Excelent con mayor puntuacion media ------ ')\ndf_Puntuacion = df_spark_sql_train.filter(\"score_string <> 'Excellent'\").groupBy('Hotel_Name').avg('Reviewer_Score')\ndf_Puntuacion.orderBy(desc(\"avg(Reviewer_Score)\")).limit(10).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">  ----  10 Hoteles no Excelent con mayor puntuacion media ------ \n+--------------------+-------------------+\n          Hotel_Name|avg(Reviewer_Score)|\n+--------------------+-------------------+\nHotel Stendhal Pl...|  9.595454545454546|\n            XO Hotel|  9.450000000000001|\n       Drawing Hotel|  9.445454545454545|\nH tel Saint Paul ...|  9.321875000000002|\n  Hotel Daniel Paris|             9.2875|\n     Splendid Etoile|  9.284931506849318|\nHotel Des Saints ...|  9.269117647058826|\nH tel Bourgogne M...|  9.243373493975904|\nHotel Beethoven Wien|  9.233035714285714|\n       H tel Le Walt|  9.227906976744187|\n+--------------------+-------------------+\n\n</div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["# Machine Learning en Apache Spark: Spark MLLib y Spark ML #"],"metadata":{}},{"cell_type":"markdown","source":["## Clasificación Supervisada: Árboles de decisión ##"],"metadata":{}},{"cell_type":"markdown","source":["### Ejercicio 6.1: Volver a observar todas las columnas del dataframe, para identificar las que sean categóricas. ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\nprint(\"   ---------- Primero imprimimos el esquema: -----------\")\nprint(df_spark_sql.printSchema())\nprint(\"   ---------- Despues imprimimos algunos datos: -----------\")\ndf_spark_sql.select('*').limit(100).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">   ---------- Primero imprimimos el esquema: -----------\nroot\n-- Hotel_Address: string (nullable = true)\n-- Additional_Number_of_Scoring: integer (nullable = true)\n-- Review_Date: string (nullable = true)\n-- Average_Score: double (nullable = true)\n-- Hotel_Name: string (nullable = true)\n-- Reviewer_Nationality: string (nullable = true)\n-- Negative_Review: string (nullable = true)\n-- Review_Total_Negative_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews: integer (nullable = true)\n-- Positive_Review: string (nullable = true)\n-- Review_Total_Positive_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews_Reviewer_Has_Given: integer (nullable = true)\n-- Reviewer_Score: double (nullable = true)\n-- Tags: string (nullable = true)\n-- days_since_review: integer (nullable = true)\n-- lat: float (nullable = true)\n-- lng: float (nullable = true)\n-- score_string: string (nullable = true)\n-- score_evaluation: integer (nullable = true)\n\nNone\n   ---------- Despues imprimimos algunos datos: -----------\n+--------------------+----------------------------+-----------+-------------+-----------+--------------------+--------------------+---------------------------------+-----------------------+--------------------+---------------------------------+------------------------------------------+--------------+--------------------+-----------------+---------+---------+------------+----------------+\n       Hotel_Address|Additional_Number_of_Scoring|Review_Date|Average_Score| Hotel_Name|Reviewer_Nationality|     Negative_Review|Review_Total_Negative_Word_Counts|Total_Number_of_Reviews|     Positive_Review|Review_Total_Positive_Word_Counts|Total_Number_of_Reviews_Reviewer_Has_Given|Reviewer_Score|                Tags|days_since_review|      lat|      lng|score_string|score_evaluation|\n+--------------------+----------------------------+-----------+-------------+-----------+--------------------+--------------------+---------------------------------+-----------------------+--------------------+---------------------------------+------------------------------------------+--------------+--------------------+-----------------+---------+---------+------------+----------------+\n s Gravesandestra...|                         194|   8/3/2017|          7.7|Hotel Arena|             Russia | I am so angry th...|                              397|                   1403| Only the park ou...|                               11|                                         7|           2.9|[&apos; Leisure trip &apos;...|                0|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|   8/3/2017|          7.7|Hotel Arena|            Ireland |         No Negative|                                0|                   1403| No real complain...|                              105|                                         7|           7.5|[&apos; Leisure trip &apos;...|                0|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|  7/31/2017|          7.7|Hotel Arena|          Australia | Rooms are nice b...|                               42|                   1403| Location was goo...|                               21|                                         9|           7.1|[&apos; Leisure trip &apos;...|                3|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|  7/31/2017|          7.7|Hotel Arena|     United Kingdom | My room was dirt...|                              210|                   1403| Great location i...|                               26|                                         1|           3.8|[&apos; Leisure trip &apos;...|                3|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|  7/24/2017|          7.7|Hotel Arena|        New Zealand | You When I booke...|                              140|                   1403| Amazing location...|                                8|                                         3|           6.7|[&apos; Leisure trip &apos;...|               10|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|  7/24/2017|          7.7|Hotel Arena|             Poland | Backyard of the ...|                               17|                   1403| Good restaurant ...|                               20|                                         1|           6.7|[&apos; Leisure trip &apos;...|               10|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|  7/17/2017|          7.7|Hotel Arena|     United Kingdom | Cleaner did not ...|                               33|                   1403| The room is spac...|                               18|                                         6|           4.6|[&apos; Leisure trip &apos;...|               17|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|  7/17/2017|          7.7|Hotel Arena|     United Kingdom | Apart from the p...|                               11|                   1403| Good location Se...|                               19|                                         1|          10.0|[&apos; Leisure trip &apos;...|               17|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|   7/9/2017|          7.7|Hotel Arena|            Belgium | Even though the ...|                               34|                   1403|         No Positive|                                0|                                         3|           6.5|[&apos; Leisure trip &apos;...|               25|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|   7/8/2017|          7.7|Hotel Arena|             Norway | The aircondition...|                               15|                   1403| The room was big...|                               50|                                         1|           7.9|[&apos; Leisure trip &apos;...|               26|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|   7/7/2017|          7.7|Hotel Arena|     United Kingdom |  Nothing all great |                                5|                   1403| Rooms were stunn...|                              101|                                         2|          10.0|[&apos; Leisure trip &apos;...|               27|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|   7/6/2017|          7.7|Hotel Arena|             France | 6 30 AM started ...|                               75|                   1403| Style location r...|                                4|                                        12|           5.8|[&apos; Business trip ...|               28|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|   7/6/2017|          7.7|Hotel Arena|     United Kingdom | The floor in my ...|                               28|                   1403| Comfy bed good l...|                                6|                                         7|           4.6|[&apos; Leisure trip &apos;...|               28|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|   7/4/2017|          7.7|Hotel Arena|              Italy |         No Negative|                                0|                   1403| This hotel is be...|                               59|                                         6|           9.2|[&apos; Business trip ...|               30|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|   7/4/2017|          7.7|Hotel Arena|             Canada | The staff in the...|                               35|                   1403| It was very good...|                               15|                                         1|           8.8|[&apos; Leisure trip &apos;...|               30|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|   7/3/2017|          7.7|Hotel Arena|              Italy |         No Negative|                                0|                   1403| This hotel is aw...|                               82|                                        26|          10.0|[&apos; Leisure trip &apos;...|               31|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|   7/3/2017|          7.7|Hotel Arena|     United Kingdom | Very steep steps...|                               38|                   1403| Great onsite caf...|                               14|                                         8|           6.3|[&apos; Leisure trip &apos;...|               31|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|  6/30/2017|          7.7|Hotel Arena|            Ireland | We did not like ...|                               59|                   1403| We loved the loc...|                               64|                                         2|           7.5|[&apos; Leisure trip &apos;...|               34|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|  6/29/2017|          7.7|Hotel Arena|        Netherlands |         No Negative|                                0|                   1403| Public areas are...|                               33|                                         4|           7.1|[&apos; Business trip ...|               35|52.360577|4.9159684|        Good|               2|\n s Gravesandestra...|                         194|  6/20/2017|          7.7|Hotel Arena|          Australia | We had issues wi...|                               73|                   1403| I liked the hote...|                               48|                                        16|           7.5|[&apos; Leisure trip &apos;...|               44|52.360577|4.9159684|        Good|               2|\n+--------------------+----------------------------+-----------+-------------+-----------+--------------------+--------------------+---------------------------------+-----------------------+--------------------+---------------------------------+------------------------------------------+--------------+--------------------+-----------------+---------+---------+------------+----------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["### Ejercicio 6.2: Eliminar, de los dataframes df_spark_sql_train y df_spark_sql test, las variables 'Hotel_Address', 'Hotel_Name', 'Tags', 'Positive Review', 'Negative_Review' y 'score_string'. Llamarlos: df_DT_train y df_DT_test. ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\ndf_DT_train = df_spark_sql_train.drop('Hotel_Address', 'Hotel_Name', 'Tags', 'Positive_Review', 'Negative_Review', 'score_string')\nprint(\"   ---------- Comprobamos que se han eliminado las columnas de df_DT_train -----------\")\nprint(df_DT_train.printSchema())\ndf_DT_test = df_spark_sql_test.drop('Hotel_Address', 'Hotel_Name', 'Tags', 'Positive_Review', 'Negative_Review', 'score_string')\nprint(\"   ---------- Comprobamos que se han eliminado las columnas de df_DT_test -----------\")\nprint(df_DT_test.printSchema())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">   ---------- Comprobamos que se han eliminado las columnas de df_DT_train -----------\nroot\n-- Additional_Number_of_Scoring: integer (nullable = true)\n-- Review_Date: string (nullable = true)\n-- Average_Score: double (nullable = true)\n-- Reviewer_Nationality: string (nullable = true)\n-- Review_Total_Negative_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews: integer (nullable = true)\n-- Review_Total_Positive_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews_Reviewer_Has_Given: integer (nullable = true)\n-- Reviewer_Score: double (nullable = true)\n-- days_since_review: integer (nullable = true)\n-- lat: float (nullable = true)\n-- lng: float (nullable = true)\n-- score_evaluation: integer (nullable = true)\n\nNone\n   ---------- Comprobamos que se han eliminado las columnas de df_DT_test -----------\nroot\n-- Additional_Number_of_Scoring: integer (nullable = true)\n-- Review_Date: string (nullable = true)\n-- Average_Score: double (nullable = true)\n-- Reviewer_Nationality: string (nullable = true)\n-- Review_Total_Negative_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews: integer (nullable = true)\n-- Review_Total_Positive_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews_Reviewer_Has_Given: integer (nullable = true)\n-- Reviewer_Score: double (nullable = true)\n-- days_since_review: integer (nullable = true)\n-- lat: float (nullable = true)\n-- lng: float (nullable = true)\n-- score_evaluation: integer (nullable = true)\n\nNone\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["### Ejercicio 7: Para cada columa restante que sea String ('Review_Date' y 'Review_Nationality'), aplicar un StringIndexer(), devolviendo como resultado la misma columna, pero con su nombre acabando en _index. Sobreescribir ambos dataframes.  ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\nfrom pyspark.ml.feature import StringIndexer\n\nprint(\"   ---------- Definimos un indexer para cada columna -----------\")\nindexerDate = StringIndexer(inputCol=\"Review_Date\", outputCol=\"Review_Date_index\")\nindexerNationality = StringIndexer(inputCol=\"Reviewer_Nationality\", outputCol=\"Reviewer_Nationality_index\")\n\nprint(\"   ---------- Ejecutamos ambos indexers sobre ambos dataframes -----------\")\ndf_DT_train = indexerDate.fit(df_DT_train).transform(df_DT_train)\ndf_DT_train = indexerNationality.fit(df_DT_train).transform(df_DT_train)\ndf_DT_test = indexerDate.fit(df_DT_test).transform(df_DT_test)\ndf_DT_test = indexerNationality.fit(df_DT_test).transform(df_DT_test)\nprint(\"   ---------- Comprobamos que se han creado las columnas de df_DT_train -----------\")\ndf_DT_train.select('Review_Date','Review_Date_Index','Reviewer_Nationality','Reviewer_Nationality_Index').limit(100).show()\nprint(\"   ---------- Comprobamos que se han creado las columnas de df_DT_test -----------\")\ndf_DT_test.select('Review_Date','Review_Date_Index','Reviewer_Nationality','Reviewer_Nationality_Index').limit(100).show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">   ---------- Definimos un indexer para cada columna -----------\n   ---------- Ejecutamos ambos indexers sobre ambos dataframes -----------\n   ---------- Comprobamos que se han creado las columnas de df_DT_train -----------\n+-----------+-----------------+--------------------+--------------------------+\nReview_Date|Review_Date_Index|Reviewer_Nationality|Reviewer_Nationality_Index|\n+-----------+-----------------+--------------------+--------------------------+\n  1/12/2016|            115.0|     United Kingdom |                       0.0|\n  1/12/2016|            115.0|     United Kingdom |                       0.0|\n  1/15/2016|            708.0|          Australia |                       2.0|\n  1/15/2016|            708.0|     United Kingdom |                       0.0|\n  1/19/2016|             44.0|            Ireland |                       3.0|\n  1/19/2016|             44.0|     United Kingdom |                       0.0|\n  1/19/2016|             44.0|     United Kingdom |                       0.0|\n  1/19/2017|            515.0|     United Kingdom |                       0.0|\n   1/2/2016|            390.0|     United Kingdom |                       0.0|\n  1/23/2016|            670.0|            Ireland |                       3.0|\n  1/24/2017|            212.0|     United Kingdom |                       0.0|\n  1/26/2016|             21.0|     United Kingdom |                       0.0|\n  1/26/2016|             21.0|     United Kingdom |                       0.0|\n  1/27/2017|            509.0|     United Kingdom |                       0.0|\n   1/3/2016|             14.0|             Israel |                      11.0|\n   1/3/2016|             14.0|     United Kingdom |                       0.0|\n   1/3/2016|             14.0|     United Kingdom |                       0.0|\n   1/3/2016|             14.0|     United Kingdom |                       0.0|\n   1/3/2017|             89.0|            Ireland |                       3.0|\n   1/5/2016|             96.0|              Malta |                      40.0|\n+-----------+-----------------+--------------------+--------------------------+\nonly showing top 20 rows\n\n   ---------- Comprobamos que se han creado las columnas de df_DT_test -----------\n+-----------+-----------------+--------------------+--------------------------+\nReview_Date|Review_Date_Index|Reviewer_Nationality|Reviewer_Nationality_Index|\n+-----------+-----------------+--------------------+--------------------------+\n  1/11/2016|            571.0|             Brazil |                      35.0|\n  1/12/2016|            123.0|     United Kingdom |                       0.0|\n  1/16/2016|            545.0|             Turkey |                      14.0|\n  1/21/2017|            609.0|            Ireland |                       3.0|\n  1/22/2016|            721.0|     United Kingdom |                       0.0|\n  1/22/2017|            362.0|        Switzerland |                       7.0|\n  1/25/2017|            432.0|       South Africa |                      18.0|\n  1/29/2017|            250.0|            Denmark |                      38.0|\n  1/30/2017|             42.0|     United Kingdom |                       0.0|\n   1/4/2017|            220.0|     United Kingdom |                       0.0|\n   1/8/2016|            699.0|     United Kingdom |                       0.0|\n  10/1/2015|            251.0|          Australia |                       2.0|\n 10/11/2016|            426.0|            Finland |                      39.0|\n 10/13/2015|             68.0|            Croatia |                      48.0|\n 10/14/2015|            618.0|             Israel |                      11.0|\n 10/18/2016|            177.0|     United Kingdom |                       0.0|\n 10/26/2016|            321.0|     United Kingdom |                       0.0|\n 10/29/2015|            163.0|     United Kingdom |                       0.0|\n  10/3/2016|            100.0|           Slovenia |                      60.0|\n 10/31/2016|             63.0|        Switzerland |                       7.0|\n+-----------+-----------------+--------------------+--------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["### Ejercicio 8: Aplicar VectorAssembler() sobre las columnas que no son ni las dos anteriores, ni la columna 'score_evaluation', devolviendo una columna llamada 'features'. Llamar al resultado DT_vector_assembler. ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\nfrom pyspark.ml.feature import VectorAssembler\n\nprint(\"   ---------- Imprimimos el esquema para ver cuales son las columnas a utilizar -----------\")\nprint(df_DT_train.printSchema())\n\nDT_vector_assembler = VectorAssembler(\n    inputCols=[\"Additional_Number_of_Scoring\", \"Average_Score\", \"Review_Total_Negative_Word_Counts\", \"Total_Number_of_Reviews\", \"Review_Total_Positive_Word_Counts\", \"Total_Number_of_Reviews_Reviewer_Has_Given\", \"Reviewer_Score\", \"days_since_review\", \"Review_Date_index\", \"Reviewer_Nationality_index\"],\n    outputCol=\"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">   ---------- Imprimimos el esquema para ver cuales son las columnas a utilizar -----------\nroot\n-- Additional_Number_of_Scoring: integer (nullable = true)\n-- Review_Date: string (nullable = true)\n-- Average_Score: double (nullable = true)\n-- Reviewer_Nationality: string (nullable = true)\n-- Review_Total_Negative_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews: integer (nullable = true)\n-- Review_Total_Positive_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews_Reviewer_Has_Given: integer (nullable = true)\n-- Reviewer_Score: double (nullable = true)\n-- days_since_review: integer (nullable = true)\n-- lat: float (nullable = true)\n-- lng: float (nullable = true)\n-- score_evaluation: integer (nullable = true)\n-- Review_Date_index: double (nullable = false)\n-- Reviewer_Nationality_index: double (nullable = false)\n\nNone\n</div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["### Ejercicio 9: Aplicar el transformador sobre ambos dataframes. ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\ndf_DT_train_assembled = DT_vector_assembler.transform(df_DT_train)\ndf_DT_test_assembled = DT_vector_assembler.transform(df_DT_test)\n\nprint(\"   ---------- Vemos el dataframe obtenido -----------\")\ndf_DT_train_assembled.select(\"*\").show(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">   ---------- Vemos el dataframe obtenido -----------\n+----------------------------+-----------+-------------+--------------------+---------------------------------+-----------------------+---------------------------------+------------------------------------------+--------------+-----------------+---------+---------+----------------+-----------------+--------------------------+--------------------+\nAdditional_Number_of_Scoring|Review_Date|Average_Score|Reviewer_Nationality|Review_Total_Negative_Word_Counts|Total_Number_of_Reviews|Review_Total_Positive_Word_Counts|Total_Number_of_Reviews_Reviewer_Has_Given|Reviewer_Score|days_since_review|      lat|      lng|score_evaluation|Review_Date_index|Reviewer_Nationality_index|            features|\n+----------------------------+-----------+-------------+--------------------+---------------------------------+-----------------------+---------------------------------+------------------------------------------+--------------+-----------------+---------+---------+----------------+-----------------+--------------------------+--------------------+\n                         194|  1/12/2016|          7.7|     United Kingdom |                                0|                   1403|                               21|                                         3|          10.0|              569|52.360577|4.9159684|               2|            115.0|                       0.0|[194.0,7.7,0.0,14...|\n                         194|  1/12/2016|          7.7|     United Kingdom |                                0|                   1403|                               13|                                         1|           9.6|              569|52.360577|4.9159684|               2|            115.0|                       0.0|[194.0,7.7,0.0,14...|\n                         194|  1/15/2016|          7.7|          Australia |                                6|                   1403|                                6|                                         1|          10.0|              566|52.360577|4.9159684|               2|            708.0|                       2.0|[194.0,7.7,6.0,14...|\n                         194|  1/15/2016|          7.7|     United Kingdom |                               60|                   1403|                               15|                                         7|           7.9|              566|52.360577|4.9159684|               2|            708.0|                       0.0|[194.0,7.7,60.0,1...|\n                         194|  1/19/2016|          7.7|            Ireland |                                9|                   1403|                                0|                                         1|           5.4|              562|52.360577|4.9159684|               2|             44.0|                       3.0|[194.0,7.7,9.0,14...|\n                         194|  1/19/2016|          7.7|     United Kingdom |                               39|                   1403|                               11|                                         1|           7.9|              562|52.360577|4.9159684|               2|             44.0|                       0.0|[194.0,7.7,39.0,1...|\n                         194|  1/19/2016|          7.7|     United Kingdom |                                9|                   1403|                                8|                                         1|           8.8|              562|52.360577|4.9159684|               2|             44.0|                       0.0|[194.0,7.7,9.0,14...|\n                         194|  1/19/2017|          7.7|     United Kingdom |                               15|                   1403|                               24|                                         1|           9.2|              196|52.360577|4.9159684|               2|            515.0|                       0.0|[194.0,7.7,15.0,1...|\n                         194|   1/2/2016|          7.7|     United Kingdom |                               63|                   1403|                               10|                                         3|           6.7|              579|52.360577|4.9159684|               2|            390.0|                       0.0|[194.0,7.7,63.0,1...|\n                         194|  1/23/2016|          7.7|            Ireland |                                0|                   1403|                               78|                                         1|          10.0|              558|52.360577|4.9159684|               2|            670.0|                       3.0|[194.0,7.7,0.0,14...|\n+----------------------------+-----------+-------------+--------------------+---------------------------------+-----------------------+---------------------------------+------------------------------------------+--------------+-----------------+---------+---------+----------------+-----------------+--------------------------+--------------------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["### Ejercicio 10: Inicializar el modelo de árbol de decisión, entrenarlo y aplicarlo sobre los datos de test. ###\n* Modelo: DecisionTreeClassifier:\n  * Label: score_evaluation.\n  * Features: features.\n  * maxBins: 1000\n  * maxDepth: 1"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml import Pipeline\n\nprint(\"   ---------- Creamos el arbol de decision para la columna score_evaluation y entrenamos el modelo con los datos TRAIN -----------\")\ndt = DecisionTreeClassifier(labelCol=\"score_evaluation\", featuresCol=\"features\", maxBins=1000, maxDepth=1)\npipeline = Pipeline(stages=[dt])\nmodel = pipeline.fit(df_DT_train_assembled)\nprint(\"   ---------- Aplicamos el modelo a los datos de TEST para obtener las previsiones y poder posteriormente evaluar el modelo -----------\")\npredictions = model.transform(df_DT_test_assembled)\n\nprint(\"   ---------- Vemos resultados obtenidos -----------\")\npredictions.select(\"score_evaluation\", \"features\", \"rawPrediction\", \"probability\", \"prediction\").show(100)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">   ---------- Creamos el arbol de decision para la columna score_evaluation y entrenamos el modelo con los datos TRAIN -----------\n   ---------- Aplicamos el modelo a los datos de TEST para obtener las previsiones y poder posteriormente evaluar el modelo -----------\n   ---------- Vemos resultados obtenidos -----------\n+----------------+--------------------+--------------------+--------------------+----------+\nscore_evaluation|            features|       rawPrediction|         probability|prediction|\n+----------------+--------------------+--------------------+--------------------+----------+\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,103.0,...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,20.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,2.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,10.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,38.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,17.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,7.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,264.0,...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,6.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,116.0,...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,18.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,15.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,45.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,15.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,8.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,21.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,12.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,13.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,73.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,13.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,8.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,55.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,23.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,46.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,85.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,4.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,40.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,11.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,176.0,...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,26.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,46.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,81.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,12.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,38.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,51.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,33.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,44.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,80.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,54.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,36.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,18.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,29.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,9.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,55.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,16.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,195.0,...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,10.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,14.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,10.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,122.0,...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,29.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,93.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,29.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,15.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,18.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,9.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,68.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,16.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,24.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,7.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,7.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,12.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,51.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,3.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,3.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,89.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,18.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,18.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,62.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,21.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,18.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,40.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,6.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,0.0,14...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,12.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,22.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n               2|[194.0,7.7,11.0,1...|[0.0,3769.0,28602...|[0.0,0.0130060147...|       2.0|\n+----------------+--------------------+--------------------+--------------------+----------+\nonly showing top 100 rows\n\n</div>"]}}],"execution_count":37},{"cell_type":"markdown","source":["### Ejercicio 11: Evaluar el modelo aplicándole un clasificador multiclase. Calcular la métrica 'accuracy', y conseguir el complementario para calcular el error. ###\n* Evaluador: MulticlassClassificationEvaluator\n  * Label: score_evaluation.\n  * Prediction: prediction.\n  * MetricName: accuracy."],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"score_evaluation\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"   ---------- Vemos error obtenido -----------\")\nprint(\"Error en el test = %g \" % (1.0 - accuracy))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">   ---------- Vemos error obtenido -----------\nError en el test = 0.0111917 \n</div>"]}}],"execution_count":39},{"cell_type":"markdown","source":["## Spark ML: Pipelines ##"],"metadata":{}},{"cell_type":"markdown","source":["### Pipelines: Árboles de Decisión ###\nCon el mismo concepto que con el KMeans, se va a diseñar el flujo para los árboles de decisión. Primero hay que aplicar los cambios de preprocesamiento vistos anteriormente al DataFrame inicial para preparalo."],"metadata":{}},{"cell_type":"markdown","source":["### Ejercicio 12: Eliminar, de los dataframes df_spark_sql_train y df_spark_sql test, las variables 'Hotel_Address', 'Hotel_Name', 'Tags', 'Positive Review', 'Negative_Review' y 'score_string'. Llamarlos: df_DT_train y df_DT_test. ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\n# Hecho en un punto anterior\n# df_DT_train = df_spark_sql_train.drop('Hotel_Address', 'Hotel_Name', 'Tags', 'Positive_Review', 'Negative_Review', 'score_string')\nprint(\"   ---------- Comprobamos que se han eliminado las columnas de df_DT_train -----------\")\nprint(df_DT_train.printSchema())\nprint(\"   ---------- Comprobamos que se han eliminado las columnas de df_DT_test -----------\")\nprint(df_DT_test.printSchema())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">   ---------- Comprobamos que se han eliminado las columnas de df_DT_train -----------\nroot\n-- Additional_Number_of_Scoring: integer (nullable = true)\n-- Review_Date: string (nullable = true)\n-- Average_Score: double (nullable = true)\n-- Reviewer_Nationality: string (nullable = true)\n-- Review_Total_Negative_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews: integer (nullable = true)\n-- Review_Total_Positive_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews_Reviewer_Has_Given: integer (nullable = true)\n-- Reviewer_Score: double (nullable = true)\n-- days_since_review: integer (nullable = true)\n-- lat: float (nullable = true)\n-- lng: float (nullable = true)\n-- score_evaluation: integer (nullable = true)\n-- Review_Date_index: double (nullable = false)\n-- Reviewer_Nationality_index: double (nullable = false)\n\nNone\n   ---------- Comprobamos que se han eliminado las columnas de df_DT_test -----------\nroot\n-- Additional_Number_of_Scoring: integer (nullable = true)\n-- Review_Date: string (nullable = true)\n-- Average_Score: double (nullable = true)\n-- Reviewer_Nationality: string (nullable = true)\n-- Review_Total_Negative_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews: integer (nullable = true)\n-- Review_Total_Positive_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews_Reviewer_Has_Given: integer (nullable = true)\n-- Reviewer_Score: double (nullable = true)\n-- days_since_review: integer (nullable = true)\n-- lat: float (nullable = true)\n-- lng: float (nullable = true)\n-- score_evaluation: integer (nullable = true)\n-- Review_Date_index: double (nullable = false)\n-- Reviewer_Nationality_index: double (nullable = false)\n\nNone\n</div>"]}}],"execution_count":43},{"cell_type":"markdown","source":["Después se diseña el flujo para este modelo, el cual será:\n\n** StringIndexer --> VectorAssembler --> Decission Tree (Inicialización) --> Decission Tree (Entrenamiento) --> Modelo Decission Tree entrenado **"],"metadata":{}},{"cell_type":"markdown","source":["### Ejercicio 13: Recoger una lista con todos los StringIndexer a aplicar, y llamarla DT_string_indexers ###\n En lugar de sobreescribir cada vez el dataframe, crear una lista, y con el método 'append', se irán añadiendo todos los StringIndexers()."],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\n\nprint(\"   ---------- Definimos un indexer para cada columna tipo string -----------\")\nDT_string_indexers = []\n\nfor name, dtype in df_DT_train.dtypes:\n  if dtype == \"string\":\n    print(\"   ---------- Definimos indexer para la columna: \", name)\n    DT_string_indexers.append(StringIndexer(inputCol=name, outputCol=name+\"_index2\"))\ndf_DT_train.printSchema() "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">   ---------- Definimos un indexer para cada columna tipo string -----------\n   ---------- Definimos indexer para la columna:  Review_Date\n   ---------- Definimos indexer para la columna:  Reviewer_Nationality\nroot\n-- Additional_Number_of_Scoring: integer (nullable = true)\n-- Review_Date: string (nullable = true)\n-- Average_Score: double (nullable = true)\n-- Reviewer_Nationality: string (nullable = true)\n-- Review_Total_Negative_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews: integer (nullable = true)\n-- Review_Total_Positive_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews_Reviewer_Has_Given: integer (nullable = true)\n-- Reviewer_Score: double (nullable = true)\n-- days_since_review: integer (nullable = true)\n-- lat: float (nullable = true)\n-- lng: float (nullable = true)\n-- score_evaluation: integer (nullable = true)\n-- Review_Date_index: double (nullable = false)\n-- Reviewer_Nationality_index: double (nullable = false)\n\n</div>"]}}],"execution_count":46},{"cell_type":"markdown","source":["### Ejercicio 14: Guardar en la variable 'DT_vector_assembler' la aplicación del mismo VectorAssembler() del ejercicio 8. ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\nDT_vector_assembler = VectorAssembler(\n    inputCols=[\"Additional_Number_of_Scoring\", \"Average_Score\", \"Review_Total_Negative_Word_Counts\", \"Total_Number_of_Reviews\", \"Review_Total_Positive_Word_Counts\", \"Total_Number_of_Reviews_Reviewer_Has_Given\", \"Reviewer_Score\", \"days_since_review\", \"Review_Date_index2\", \"Reviewer_Nationality_index2\"],\n    outputCol=\"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":48},{"cell_type":"markdown","source":["### Ejercicio 15: Crear una lista con el mombre de DT_pipeline_stages, y añadirle la lista de StringIndexers y el VectorAssembler (en este orden) ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\nDT_pipeline_stages = []\n# Añadir la lista de String Indexers\nDT_pipeline_stages = [str_indexer for str_indexer in DT_string_indexers]\nDT_pipeline_stages.append(DT_vector_assembler)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":50},{"cell_type":"markdown","source":["### Ejercicio 16: Inicializar el modelo de árbol de decisión (mismas especificaciones que en el ej. 10), y añadirlo a la lista de pasos 'DT_pipeline_stages' ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\nprint(\"   ---------- Creamos el arbol de decision para la columna score_evaluation y entrenamos el modelo con los datos TRAIN -----------\")\ndt_pipeline = DecisionTreeClassifier(labelCol=\"score_evaluation\", featuresCol=\"features\", maxBins=1000, maxDepth=1)\nDT_pipeline_stages.append(dt_pipeline)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">   ---------- Creamos el arbol de decision para la columna score_evaluation y entrenamos el modelo con los datos TRAIN -----------\n</div>"]}}],"execution_count":52},{"cell_type":"markdown","source":["### Ejercicio 17: Diseñar el Pipeline y aplicarlo sobre los datos de Train, llamándolo 'DT_pipeline_model' ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\n\n# Definimos el pipeline a partir de los pasos anteriores\npipeline_list = Pipeline(stages=DT_pipeline_stages)\n\n# Aplicamos el pipeline sobre los datos TRAIN:\nDT_pipeline_model = pipeline_list.fit(df_DT_train)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":54},{"cell_type":"markdown","source":["### Ejercicio 18: Aplicar el modelo resultante sobre los datos de test y evaluarlo al igual que se hizo en el ej. 11 ###"],"metadata":{}},{"cell_type":"code","source":["# Escribir aquí el ejercicio\nDT_predictions = DT_pipeline_model.transform(df_DT_test)\nDT_predictions.select(\"score_evaluation\", \"features\", \"rawPrediction\", \"probability\", \"prediction\").show(100)\n\nprint(predictions.dtypes)\nprint(DT_predictions.dtypes)\n\nprint(type(predictions))\nprint(type(DT_predictions))\n\ndtModel = DT_pipeline_model.stages[len(DT_pipeline_model.stages)-1]\nevaluator2 = MulticlassClassificationEvaluator(\n    labelCol=\"score_evaluation\", predictionCol=\"prediction\", metricName=\"accuracy\")\n# No entiendo que esta expresion de error...\naccuracy2 = evaluator2.evaluate(DT_predictions)\nprint(\"   ---------- Vemos error obtenido -----------\")\nprint(\"Error en el test = %g \" % (1.0 - accuracy2))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-4027673054087877&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     12</span> evaluator2 = MulticlassClassificationEvaluator(\n<span class=\"ansigreen\">     13</span>     labelCol=&quot;score_evaluation&quot;, predictionCol=&quot;prediction&quot;, metricName=&quot;accuracy&quot;)\n<span class=\"ansigreen\">---&gt; 14</span><span class=\"ansiyellow\"> </span>accuracy2 <span class=\"ansiyellow\">=</span> evaluator2<span class=\"ansiyellow\">.</span>evaluate<span class=\"ansiyellow\">(</span>DT_predictions<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     15</span> print<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;   ---------- Vemos error obtenido -----------&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     16</span> print<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Error en el test = %g &quot;</span> <span class=\"ansiyellow\">%</span> <span class=\"ansiyellow\">(</span><span class=\"ansicyan\">1.0</span> <span class=\"ansiyellow\">-</span> accuracy<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/evaluation.py</span> in <span class=\"ansicyan\">evaluate</span><span class=\"ansiblue\">(self, dataset, params)</span>\n<span class=\"ansigreen\">     67</span>                 <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>copy<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_evaluate<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     68</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 69</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_evaluate<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     70</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     71</span>             <span class=\"ansigreen\">raise</span> ValueError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Params must be a param map but got %s.&quot;</span> <span class=\"ansiyellow\">%</span> type<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/evaluation.py</span> in <span class=\"ansicyan\">_evaluate</span><span class=\"ansiblue\">(self, dataset)</span>\n<span class=\"ansigreen\">     97</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">     98</span>         self<span class=\"ansiyellow\">.</span>_transfer_params_to_java<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 99</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_java_obj<span class=\"ansiyellow\">.</span>evaluate<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    100</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    101</span>     <span class=\"ansigreen\">def</span> isLargerBetter<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1131</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1132</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1133</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1134</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1135</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     61</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    317</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    318</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}.\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 319</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name), value)\n</span><span class=\"ansigreen\">    320</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    321</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o1052.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 89.0 failed 1 times, most recent failure: Lost task 5.0 in stage 89.0 (TID 1329, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$5: (string) =&gt; double)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:423)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:111)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:354)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Unseen label:  Anguilla .  To handle unseen labels, set Param handleInvalid to keep.\n\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$5.apply(StringIndexer.scala:222)\n\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$5.apply(StringIndexer.scala:208)\n\t... 16 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1683)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1671)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1670)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1670)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:931)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:931)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:931)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1903)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1854)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1842)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:733)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2119)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2140)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2159)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2184)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:947)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:371)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:946)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:743)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:742)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:371)\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:742)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass$lzycompute(MulticlassMetrics.scala:48)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass(MulticlassMetrics.scala:44)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy$lzycompute(MulticlassMetrics.scala:168)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy(MulticlassMetrics.scala:168)\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator.evaluate(MulticlassClassificationEvaluator.scala:87)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:293)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:226)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$5: (string) =&gt; double)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:423)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:111)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:354)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: Unseen label:  Anguilla .  To handle unseen labels, set Param handleInvalid to keep.\n\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$5.apply(StringIndexer.scala:222)\n\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$5.apply(StringIndexer.scala:208)\n\t... 16 more\n</div>"]}}],"execution_count":56}],"metadata":{"name":"AnaliticaEscalablePySparkEjercicios","notebookId":4027673054087821},"nbformat":4,"nbformat_minor":0}
