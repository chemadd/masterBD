{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal para reproducir la funcion XNOR de 3 valores de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Preparamos el entorno\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# %config blas.ldflags = '-lblas'\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "# print (T.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos funciones utiles\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype = theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    # Devuelve pesos aleatorios para una matriz con las filas y columnas \n",
    "    # pasadas como parametro\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def modelo_RNXOR_3_2(entrada, salida, iteraciones):\n",
    "    # Modelo de red neuronal de 3 neuronas a la entrada y dos a la salida,\n",
    "    # para generar la funcion XOR\n",
    "    \n",
    "    # Matrices de pesos de las capas de entrada y salida y Bias\n",
    "    w_input = init_weights((3,2))\n",
    "    print(w_input.get_value())\n",
    "    w_output = init_weights((2,1))\n",
    "    print(w_output.get_value())\n",
    "    b1 = theano.shared(1.)\n",
    "    b2 = theano.shared(1.)\n",
    "    \n",
    "    # Definimos los valores de entrada y Salida\n",
    "    X = T.fmatrix()\n",
    "    Y = T.fmatrix()\n",
    "    # Creamos la red neuronal. En primera capa con sigmoide, en segunda con softmax\n",
    "    Sal_Capa1 = T.nnet.sigmoid(T.dot(X, w_input)+b1)\n",
    "    Sal_CapaFin = T.nnet.softmax(T.dot(Sal_Capa1, w_output)+b2)\n",
    "    # Nos quedamos con el valor con mayor probabilidad\n",
    "    respuesta = T.argmax(Sal_CapaFin, axis=1)\n",
    "    # respuesta = Sal_CapaFin[T.argmax(Sal_CapaFin)]\n",
    "    print('----------------------------------------')\n",
    "    print(respuesta.type, respuesta.ndim)\n",
    "    print('----------------------------------------')\n",
    "    print(respuesta.flatten)\n",
    "    \n",
    "    # Entrenamos la red neuronal, para lo que definimos una funcion de coste\n",
    "    f_coste = T.nnet.binary_crossentropy(respuesta, Y).mean()\n",
    "    # f_coste = T.mean(T.nnet.binary_crossentropy(Sal_CapaFin, Y))\n",
    "    # Tambien una funcion de ajuste de pesos y bias para propagacion del error\n",
    "    ajuste = T.grad(f_coste, [w_input, w_output] )\n",
    "    print(*ajuste)\n",
    "    aprendizaje = []\n",
    "    for inp, aju in zip([w_input, w_output], ajuste):\n",
    "        aprendizaje.append([inp, inp - aju * 0.01])\n",
    "        \n",
    "    print('aprendizaje:')\n",
    "    for ind in range(len(aprendizaje)):\n",
    "        print(*aprendizaje[ind])\n",
    "    # Definimos la funcion de entrenamiento\n",
    "    f_train = theano.function (\n",
    "          inputs = [X,Y],\n",
    "          outputs = [respuesta, f_coste] ,\n",
    "          updates = aprendizaje,\n",
    "          allow_input_downcast = True\n",
    "        )\n",
    "    # Definimos la funcion de ejecucion de la red:\n",
    "    f_predict = theano.function (\n",
    "          inputs= [X],\n",
    "          outputs = respuesta,\n",
    "          allow_input_downcast = True\n",
    "        )\n",
    "    \n",
    "    # Iteramos hasta obtener el resultado:\n",
    "    cost = []\n",
    "    for i in range(iteraciones):\n",
    "        pred, cost_iter = f_train(entrada, salida)\n",
    "        # print(pred)\n",
    "        cost.append(cost_iter)\n",
    "    # Se imprimen los resultados por pantalla\n",
    "    print('Los resultados de la red son:')\n",
    "    for i in range(len(entrada)):\n",
    "        print('El resultado para [%d, %d, %d] es %.2f' % (inputs[i][0], inputs[i][1], inputs[i][2], pred[i]))\n",
    "    \n",
    "    # Función de esfuerzo en función del número de iteraciones\n",
    "    plt.plot(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0]\n",
      "[0, 0, 1]\n",
      "[0, 1, 0]\n",
      "[0, 1, 1]\n",
      "[1, 0, 0]\n",
      "[1, 0, 1]\n",
      "[1, 1, 0]\n",
      "[1, 1, 1]\n",
      "[[-0.01944644  0.00354864]\n",
      " [-0.00397421  0.0007802 ]\n",
      " [-0.00741165 -0.01417206]]\n",
      "[[ 0.00890333]\n",
      " [-0.01078799]]\n",
      "----------------------------------------\n",
      "TensorType(int64, vector) 1\n",
      "----------------------------------------\n",
      "<bound method _tensor_py_operators.flatten of argmax>\n",
      "dot.0 dot.0\n",
      "aprendizaje:\n",
      "<TensorType(float64, matrix)> Elemwise{sub,no_inplace}.0\n",
      "<TensorType(float64, matrix)> Elemwise{sub,no_inplace}.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input dimension mis-match. (input[0].shape[0] = 1, input[1].shape[0] = 8)\nApply node that caused the error: Elemwise{Composite{((i0 * i1) + (i2 * log1p((-i3))))}}[(0, 1)](<TensorType(float32, matrix)>, LogSoftmax.0, Elemwise{sub,no_inplace}.0, Softmax.0)\nToposort index: 21\nInputs types: [TensorType(float32, matrix), TensorType(float64, matrix), TensorType(float32, matrix), TensorType(float64, matrix)]\nInputs shapes: [(1, 8), (8, 1), (1, 8), (8, 1)]\nInputs strides: [(32, 4), (8, 8), (32, 4), (8, 8)]\nInputs values: ['not shown', 'not shown', 'not shown', 'not shown']\nOutputs clients: [[Sum{acc_dtype=float64}(Elemwise{Composite{((i0 * i1) + (i2 * log1p((-i3))))}}[(0, 1)].0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input dimension mis-match. (input[0].shape[0] = 1, input[1].shape[0] = 8)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-27d40b766e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodelo_RNXOR_3_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-188-4d03c7c2181a>\u001b[0m in \u001b[0;36mmodelo_RNXOR_3_2\u001b[0;34m(entrada, salida, iteraciones)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteraciones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentrada\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msalida\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;31m# print(pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input dimension mis-match. (input[0].shape[0] = 1, input[1].shape[0] = 8)\nApply node that caused the error: Elemwise{Composite{((i0 * i1) + (i2 * log1p((-i3))))}}[(0, 1)](<TensorType(float32, matrix)>, LogSoftmax.0, Elemwise{sub,no_inplace}.0, Softmax.0)\nToposort index: 21\nInputs types: [TensorType(float32, matrix), TensorType(float64, matrix), TensorType(float32, matrix), TensorType(float64, matrix)]\nInputs shapes: [(1, 8), (8, 1), (1, 8), (8, 1)]\nInputs strides: [(32, 4), (8, 8), (32, 4), (8, 8)]\nInputs values: ['not shown', 'not shown', 'not shown', 'not shown']\nOutputs clients: [[Sum{acc_dtype=float64}(Elemwise{Composite{((i0 * i1) + (i2 * log1p((-i3))))}}[(0, 1)].0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "# Conjunto de datos de entrenamiento\n",
    "inputs = [[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 0, 1], [1, 1, 0] , [1, 1, 1]]\n",
    "outputs = [[0, 1, 1, 0, 1, 0, 0, 1]]\n",
    "\n",
    "for ind in range(len(inputs)):\n",
    "    print(inputs[ind])\n",
    "\n",
    "modelo_RNXOR_3_2(inputs, outputs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
